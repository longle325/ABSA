# PhoBERT + BiLSTM-CRF Model Configuration
# ========================================

model:
  name: "phobert-bilstm-crf"
  pretrained: "vinai/phobert-base"   # HuggingFace model name

# Architecture Settings
architecture:
  lstm_hidden: 256             # LSTM hidden size
  lstm_layers: 2               # Number of LSTM layers
  dropout: 0.1                 # Dropout rate
  lstm_dropout: 0.3            # LSTM dropout rate
  freeze_bert: false           # Freeze PhoBERT weights

# Training Settings
training:
  epochs: 20                   # Number of training epochs
  batch_size: 16               # Batch size
  gradient_clip: 1.0           # Gradient clipping value
  warmup_ratio: 0.1            # Warmup ratio for learning rate
  early_stopping_patience: 5   # Early stopping patience

# Optimizer Settings
optimizer:
  bert_lr: 2.0e-5              # Learning rate for PhoBERT
  lstm_lr: 1.0e-3              # Learning rate for LSTM
  crf_lr: 1.0e-2               # Learning rate for CRF
  weight_decay: 0.01           # Weight decay

# Device Settings
device:
  use_cuda: true               # Use GPU if available
  fp16: false                  # Use mixed precision training
